{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Notebook for Building Pipeline Using Module 'concat_two_files'\n",
    "The module 'concat_two_files' was generated through command: 'az ml module init -n concat_two_files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.pipeline.wrapper import Module, Pipeline, dsl\n",
    "import sys\n",
    "from pathlib import Path\n",
    "# The following line adds source directory to path. \n",
    "from concat_two_files_entry import concat_two_files"
   ]
  },
  {
   "source": [
    "## Prerequisites: Configure workspace & compute\n",
    "\n",
    " - Update .azureml/config.json to make sure it has information on your workspace, subscription id, etc.\n",
    " - Change the following aml_compute_target's value to reference an existing compute target"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace = Workspace.from_config(path = '.azureml/config.json')\n",
    "aml_compute_target = \"YOUR_COMPUTE_TARGET\"\n",
    "print(workspace.name, workspace.resource_group, workspace.location, workspace.subscription_id, aml_compute_target, sep='\\n')"
   ]
  },
  {
   "source": [
    "# Load module(s)\n",
    "Load a module function through one of the following:\n",
    "- Module.from_func: when you have a python function decorated with @dsl.module\n",
    "- Module.from_yaml: when loading from existing module yaml definition\n",
    "- Module.load: when you have already registered the module into Azure ML workspace"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_func = Module.from_func(workspace, concat_two_files)\n",
    "help(module_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run module in local\n",
    "Using module.run can execute module in local machine<br>\n",
    "If use_docker=True, will pull image from azure and run module in container.<br>\n",
    "If use_docker=False, will directly run module script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create module\n",
    "module = module_func().set_parameters(\n",
    "    append_line_break=False\n",
    ").set_inputs(\n",
    "    input1=str(Path('data') / 'concat_two_files_entry' / 'inputs' / 'input1'), input2=str(Path('data') / 'concat_two_files_entry' / 'inputs' / 'input2')\n",
    ")\n",
    "module.run(use_docker=True)"
   ]
  },
  {
   "source": [
    "# Create pipeline\n",
    "This is done by calling module function(s) with the parameters/inputs/outputs the module supports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataset with the following code \n",
    "\n",
    "# from azureml.core import Dataset\n",
    "\n",
    "# your_dataset = Dataset.get_by_name(workspace, name='YOUR_DATASET_NAME')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name='concat_two_files_pipeline', description='A sample pipeline uses concat_two_files', default_compute_target=aml_compute_target)\n",
    "def sample_pipeline() -> Pipeline:\n",
    "    module1 = module_func().set_parameters(\n",
    "    \n",
    "    ).set_inputs(\n",
    "        # Please fill required inputs here\n",
    "        # input1=None, input2=None\n",
    "    )\n",
    "    \n",
    "    return module1.outputs\n",
    "\n",
    "test_pipeline = sample_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipeline.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = test_pipeline.submit(\n",
    "    experiment_name='concat_two_files_experiment'\n",
    ")\n",
    "run.wait_for_completion()\n",
    "run"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}